# -*- coding: utf-8 -*-
"""Smart_City_Traffic_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vHl-WbygyxezaEW6xrZWadd0Mo_00P3-

# **Import libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

"""# **1. Load Data**"""

train_df=pd.read_csv('train_aWnotuB.csv')
test_df=pd.read_csv('datasets_8494_11879_test_BdBKkAj.csv')

"""**Preview train data**"""

print("Train Data:")
train_df.head()

print("Train Data:")
train_df.shape

print("Train Data:")
train_df.info()

print("Train Data:")
train_df.describe()

"""**Data Cleaning**"""

train_df.isnull().sum()

print(f"\nTrain duplicate rows: {train_df.duplicated().sum()}")

"""# **2) Feature Engineering**"""

def feature_engineering(df):
    # Convert DateTime column to datetime type
    df['DateTime'] = pd.to_datetime(df['DateTime'])

    # Extract time-based features
    df['Hour'] = df['DateTime'].dt.hour
    df['Day'] = df['DateTime'].dt.day
    df['Weekday'] = df['DateTime'].dt.weekday  # Monday=0, Sunday=6
    df['Month'] = df['DateTime'].dt.month
    df['Year'] = df['DateTime'].dt.year
    df['Weekday_Name'] = df['DateTime'].dt.day_name()  # For EDA

    # Create binary flags:
    df['Is_Weekend'] = df['Weekday'].isin([5, 6]).astype(int)
    df['Is_Night'] = df['Hour'].isin(range(0, 6)).astype(int)

    # You can add additional features, like:
    # Sine/cosine transformation for cyclic features (Hour, Month)
    # Hour_sin and Hour_cos map hours into a circle (clock).
    # Now the model understands that Hour 23 and Hour 0 are close.
    # Same applies for Month, Weekday, or any other cyclical feature.
    df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)
    df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)
    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)
    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)

    return df

"""**Apply feature engineering to train and test data**"""

train_df = feature_engineering(train_df)
test_df  = feature_engineering(test_df)

"""**Check features**"""

print("\nEngineered Training Data:")
print(train_df.head())

"""# **3. Exploratory Data Analysis (EDA)**"""

sns.set(style="whitegrid")

""" **Plot 1: Overall traffic trend (sampled for visualization)**"""

plt.figure(figsize=(14,4))
sampled=train_df.sample(min(2000, len(train_df)))
sns.lineplot(data=sampled, x='DateTime', y='Vehicles',hue='Junction', palette='tab10')
plt.title("Traffic Volume Trend Over Time (Sampled)")
plt.xlabel("Date")
plt.ylabel("Vehicle count")
plt.legend(title="Junction")
plt.tight_layout()
plt.show()

"""**Plot 2: Average hourly traffic per junction**"""

plt.figure(figsize=(12,5))
hourly_mean=train_df.groupby(['Hour','Junction'])['Vehicles'].mean().reset_index()
sns.lineplot(data=hourly_mean, x='Hour', y='Vehicles', hue='Junction', palette='tab10')
plt.title("Average Hourly Traffic per Junction")
plt.xlabel("Hour of the Day")
plt.ylabel("Average Vehicles count")
plt.legend(title="Junction")
plt.tight_layout()
plt.show()

"""**Plot 3: Average traffic by weekday**"""

plt.figure(figsize=(10,5))
weekday_order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
sns.barplot(data=train_df, x='Weekday_Name', y='Vehicles', hue='Junction', order=weekday_order)
plt.title("Average Traffic by Weekday per Junction")
plt.xlabel("Weekday")
plt.ylabel("Average Vehicles count")
plt.legend(title="Junction")
plt.tight_layout()
plt.show()

"""**Plot 4: Monthly Trend per Junction**"""

plt.figure(figsize=(10, 5))
monthly_mean = train_df.groupby(['Month', 'Junction'])['Vehicles'].mean().reset_index()
sns.lineplot(data=monthly_mean, x='Month', y='Vehicles', hue='Junction', palette='tab10')
plt.title("Average Monthly Traffic Volume per Junction")
plt.xlabel("Month")
plt.ylabel("Average Vehicle Count")
plt.tight_layout()
plt.show()

"""**Plot 5: Weekend vs Weekday Distribution**"""

plt.figure(figsize=(8, 5))
sns.boxplot(data=train_df, x='Is_Weekend', y='Vehicles', hue='Junction')
plt.title("Weekend vs Weekday Traffic Distribution")
plt.xlabel("Is Weekend (0=Weekday, 1=Weekend)")
plt.ylabel("Vehicle Count")
plt.legend(title="Junction")
plt.tight_layout()
plt.show()

"""# **4. Modeling**"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from lightgbm import LGBMRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import lightgbm as lgb

"""**For modeling, we select features that are not raw DateTime/text identifiers.**"""

features = ['Junction', 'Hour', 'Day', 'Weekday', 'Month', 'Year',
            'Is_Weekend', 'Is_Night', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos']
target = 'Vehicles'

"""**Prepare train data**"""

X = train_df[features]
y = train_df[target]

X['Junction'] = X['Junction'].astype('category')
if 'Junction' in test_df.columns:
    test_df['Junction'] = test_df['Junction'].astype('category')

"""**Split into training and validation sets (e.g., 80/20 split)**"""

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

"""**1) LightGBM**

**Set parameters for LightGBM regression and Train the model with early stopping**
"""

# Junction' is categorical
X_train['Junction'] = X_train['Junction'].astype('category')
X_valid['Junction'] = X_valid['Junction'].astype('category')

# Initialize LightGBM Regressor
model = LGBMRegressor(
    objective='regression',
    learning_rate=0.05,
    num_leaves=31,
    n_estimators=1500,
    random_state=42
)

# Train with both train and valid sets included in eval_set
model.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_valid, y_valid)],
    eval_metric='rmse',
    callbacks=[
        lgb.early_stopping(50),
        lgb.log_evaluation(period=1)  # Logs train & valid RMSE every round
    ]
)

"""**2) XGBoost Regressor**"""

import xgboost as xgb

# Convert to DMatrix format
dtrain = xgb.DMatrix(X_train, label=y_train)
dvalid = xgb.DMatrix(X_valid, label=y_valid)

# Define parameters
params = {
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'learning_rate': 0.05,
    'max_depth': 6,
    'seed': 42
}

# Train using xgb.train (core API)
watchlist = [(dtrain, 'train'), (dvalid, 'valid')]
xgb_model = xgb.train(
    params,
    dtrain,
    num_boost_round=1000,
    evals=watchlist,
    early_stopping_rounds=50,
    verbose_eval=100
)

"""LightGbm is the best model

**Predict on validation set and evaluate**
"""

y_pred = model.predict(X_valid, num_iteration=model.best_iteration_) # model=lightgbm
rmse = np.sqrt(mean_squared_error(y_valid, y_pred))
r2 = r2_score(y_valid, y_pred)
print(f"\nValidation MAE: {mae:.2f}")
print(f"Validation RMSE: {rmse:.2f}")
print(f"Validation RÂ²   : {r2:.2f}")

"""# **5. Test Prediction**

**Prepare test features (ensure same processing as train)**
"""

X_test = test_df[features]
X_test['Junction'] = X_test['Junction'].astype('category')

"""**Predict on test data using the best iteration from training**"""

test_df['Vehicles'] = model.predict(X_test, num_iteration=model.best_iteration_)

# If the test file requires a specific submission format, adjust accordingly.
# For example, if a submission file requires 'ID' and predicted 'Vehicles':
if 'ID' in test_df.columns:
    submission = test_df[['ID', 'Vehicles']]
else:
    # Otherwise, create an index-based submission
    submission = test_df.copy()

"""**Saving submission file**"""

submission.to_csv("submission.csv", index=False)
print("\nSubmission file saved as 'submission.csv'.")

